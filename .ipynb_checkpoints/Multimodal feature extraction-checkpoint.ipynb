{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodal feature generation\n",
    "\n",
    "Example code to extract features from several different modalities, such as time, coordinates, textual and visual.\n",
    "\n",
    "For reference purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove this, add to the designated section\n",
    "\n",
    "import pandas as pd\n",
    "import ast\n",
    "from datetime import datetime, timedelta\n",
    "import requests\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os\n",
    "import gensim\n",
    "from sklearn.metrics import classification_report\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from string import punctuation\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Import pandas as pd\n",
    "\n",
    "df = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time\n",
    "Create columns for time features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "signal['created_at'] = pd.to_datetime(signal['created_at'])\n",
    "signal['weekday'] = signal['created_at'].map(lambda x: x.weekday())\n",
    "signal['hour'] = signal['created_at'].map(lambda x: x.hour)\n",
    "signal['week'] = signal['created_at'].map(lambda x: x.week)\n",
    "signal['dayofyear'] = signal['created_at'].map(lambda x: x.dayofyear)\n",
    "signal['month'] = signal['created_at'].map(lambda x: x.month)\n",
    "signal['date'] = pd.to_datetime(signal['created_at']).map(lambda x: str(x).split(' ')[0].replace('-',''))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some classifiers features require to be one hot encoded, this can easiliy be done with pandas and sklearn, as can be seen in the code snippit below\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the following features and one hot encode them. \n",
    "one_hot = ['weekday', 'hour', 'month']\n",
    "\n",
    "for c in one_hot:\n",
    "    keep = list(df.columns)\n",
    "    keep.remove(c)\n",
    "    signal = pd.concat([df[keep],pd.get_dummies(df[c], prefix='time_'+c)],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather\n",
    "\n",
    "Convert hourly datetime to weather recorded at schiphol airport\n",
    "\n",
    "Data source and information about columns can be found at: https://projects.knmi.nl/klimatologie/uurgegevens/selectie.cgi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = pd.read_csv('knmi.csv')\n",
    "weather.columns = weather.columns.str.replace(' ', '')\n",
    "\n",
    "def get_weather_dict(date,hour):\n",
    "\n",
    "    weather_at_time = weather[weather['YYYYMMDD'].astype(str)==date][weather['HH'].astype(int)==hour+1].reset_index(drop=True)\n",
    "    weather_at_time = weather_at_time[['IX', 'M', 'R', 'S', 'O','Y','DD', 'FH', 'FF', 'FX', 'T', 'TD', 'SQ','Q', 'DR', 'RH', 'P', 'U']]\n",
    "    \n",
    "    weather_dict = {}\n",
    "    for key, value in weather_at_time.to_dict().items():\n",
    "        try:\n",
    "            weather_dict['weather_'+key] = value[0]\n",
    "        except:\n",
    "            weather_dict['weather_'+key] = 0\n",
    "    return weather_dict\n",
    "\n",
    "signal['weather_dict'] = signal.apply(lambda row: get_weather_dict(row.date,row.hour), axis=1)\n",
    "for column in list(signal['weather_dict'][0].keys()):\n",
    "    signal[column] = signal['weather_dict'].map(lambda d: d[column])\n",
    "del signal['weather_dict']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geo semantic\n",
    "\n",
    "Creating a profile of the area arround the given coordinates using data from https://maps.amsterdam.nl/open_geodata/?LANG=en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def haversine_est(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Estimation with equirectangular distance approximation. \n",
    "    Since the distance is relatively small, you can use the equirectangular distance approximation. \n",
    "    This approximation is faster than using the Haversine formula. \n",
    "    So, to get the distance from your reference point (lat1/lon1) to the point your are testing (lat2/lon2),\n",
    "    use the formula below. \n",
    "    Important Note: you need to convert all lat/lon points to radians:\n",
    "    \"\"\"\n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    x = (lon2 - lon1) * np.cos( 0.5*(lat2+lat1) )\n",
    "    y = lat2 - lat1\n",
    "    km = 6371.0 * np.sqrt( x*x + y*y )\n",
    "    return km\n",
    "\n",
    "def generate_geo_dict(semantic_name,lat,lng,semantic_lats,semantic_lngs):\n",
    "    \n",
    "    geo_dict = {}\n",
    "\n",
    "    distances = []\n",
    "    for i in range(len(semantic_lats)):\n",
    "        distances.append(haversine_est(lat,lng,semantic_lngs[i], semantic_lats[i]))\n",
    "    distances = sorted(distances)\n",
    "    if distances[0]>100:\n",
    "        print('distance of ',distances[0])\n",
    "    geo_dict['geo_'+semantic_name+'_nearest'] = distances[0]\n",
    "    geo_dict['geo_'+semantic_name+'_nearest_5_mean'] = np.mean(distances[:5])\n",
    "    geo_dict['geo_'+semantic_name+'_nearest_10_mean'] = np.mean(distances[:10])\n",
    "    geo_dict['geo_'+semantic_name+'_nearest_100_mean'] = np.mean(distances[:100])\n",
    "\n",
    "    \n",
    "    geo_dict['geo_'+semantic_name+'_within_25m']  = 0\n",
    "    geo_dict['geo_'+semantic_name+'_within_50m']  = 0\n",
    "    geo_dict['geo_'+semantic_name+'_within_100m'] = 0\n",
    "    geo_dict['geo_'+semantic_name+'_within_200m'] = 0\n",
    "    \n",
    "    for distance in distances:\n",
    "\n",
    "        if distance <0.025:\n",
    "            geo_dict['geo_'+semantic_name+'_within_25m'] += 1\n",
    "        if distance <0.05:\n",
    "            geo_dict['geo_'+semantic_name+'_within_50m'] += 1 \n",
    "        if distance <0.1:\n",
    "            geo_dict['geo_'+semantic_name+'_within_100m'] += 1 \n",
    "        if distance <0.2:\n",
    "            geo_dict['geo_'+semantic_name+'_within_200m'] += 1    \n",
    "        \n",
    "    return geo_dict\n",
    "    \n",
    "def load_geo_features(signal,description,column,csv,sep,minimal_number=100):\n",
    "    \n",
    "    decription = description.lower()\n",
    "    df = pd.read_csv(csv,sep=sep)\n",
    "\n",
    "\n",
    "    # add more kinds of data, trees, bars, benches, on water or not\n",
    "    keep = df[column].value_counts().to_frame()\n",
    "    keep = list(keep[keep[column]>minimal_number].index)\n",
    "    print(len(keep), 'loading types of ',csv)\n",
    "\n",
    "    for t in keep:\n",
    "        print(t,len(df[df[column]==t]))\n",
    "        try:\n",
    "            lats = [float(x.replace(',','.')) for x in list(df[df[column]==t]['LAT'])]\n",
    "            lngs = [float(x.replace(',','.')) for x in list(df[df[column]==t]['LNG'])]\n",
    "        except:            \n",
    "            lats = list(df[df[column]==t]['LAT'])\n",
    "            lngs = list(df[df[column]==t]['LNG'])\n",
    "        t = t.lower()\n",
    "        signal['geo_'+description+'_'+t+'_dict'] = signal.apply(lambda row: generate_geo_dict(description+'_'+t,row.lat,row.lng,lats,lngs), axis=1)\n",
    "        \n",
    "\n",
    "        for c in list(signal['geo_'+description+'_'+t+'_dict'][0].keys()):\n",
    "            signal[c] = signal['geo_'+description+'_'+t+'_dict'].map(lambda d: d[c])\n",
    "        del signal['geo_'+description+'_'+t+'_dict']\n",
    "    return signal\n",
    "\n",
    "# change to a single file, and add file\n",
    "signal = load_geo_features(signal,'container','waste_name','containers_with_type.csv',',',100)\n",
    "\n",
    "signal = load_geo_features(signal,'trees','Soortnaam_NL','soorten_bomen.csv',',',100)\n",
    "\n",
    "signal = load_geo_features(signal,'business','FUNCTIE2_OMS','FUNCTIEKAART.csv',';',100)\n",
    "\n",
    "signal = load_geo_features(signal,'monument','Status','MONUMENTEN.csv',';',100)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Textual features\n",
    "\n",
    "Create word count features for 5000 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "def get_top_n_words(corpus, n=None):\n",
    "    vec = CountVectorizer(stop_words=set(stopwords.words('dutch'))).fit(corpus) # or for example a tf-idf vectorizer could be used\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in     vec.vocabulary_.items()]\n",
    "    words_freq = sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "\n",
    "words_count = get_top_n_words(signal['text'],5000)\n",
    "\n",
    "signal['text'] = signal['text'].map(lambda x: x.lower())\n",
    "\n",
    "for word_count in tqdm(words_count):\n",
    "    word = word_count[0]\n",
    "    count = word_count[1]\n",
    "    signal['text_'+word] = signal['text'].map(lambda x: x.count(word)).astype(int)\n",
    "\n",
    "del signal['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual features\n",
    "\n",
    "Extracting the 50 visual concepts of each image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "model = ResNet50(weights='imagenet')\n",
    "\n",
    "images_path = ''\n",
    "\n",
    "images_ids = [int(x.split('.')[0]) for x in os.listdir(images_path)]\n",
    "\n",
    "\n",
    "def get_image_output_layer(x):\n",
    "\n",
    "    image_text = ''\n",
    "    if x in images_ids:\n",
    "\n",
    "        image_path = images_path+str(x)+'.jpg'\n",
    "        img = image.load_img(image_path, target_size=(224, 224))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "\n",
    "        preds = model.predict(x)\n",
    "\n",
    "\n",
    "        return decode_predictions(preds, top=50)[0]\n",
    "\n",
    "\n",
    "    return ''\n",
    "\n",
    "i = images_ids[1]\n",
    "\n",
    "df['image_objects_50'] = df['id'].progress_apply(get_image_output_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual 2024 features\n",
    "This function can be used to convert any image to a 2024 dimensions representation of the image using imagenet and ResNet\n",
    "\n",
    "Getting last layer: https://keras.io/getting-started/faq/#how-can-i-obtain-the-output-of-an-intermediate-layer\n",
    "\n",
    "The hidden representation of the last layer (before the softmax) is often taken as a feature vector, as it contains higher level features\n",
    "\n",
    "https://github.com/keras-team/keras-applications/blob/master/keras_applications/resnet50.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_layer_before_softmax(x):\n",
    "    '''\n",
    "    Inputs a file name\n",
    "    Outputs a 2024 dimensional representation of an image\n",
    "    '''\n",
    "\n",
    "    if x in images_ids:\n",
    "\n",
    "        # load image setting the image size to 224 x 224\n",
    "        img = image.load_img(images_path + str(x)+\".jpg\", target_size=(224, 224))\n",
    "        # convert image to numpy array\n",
    "        x = image.img_to_array(img)\n",
    "        # the image is now in an array of shape (3, 224, 224) \n",
    "        # need to expand it to (1, 3, 224, 224) as it's expecting a list\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "\n",
    "        # with a Sequential model\n",
    "        number_of_layers = len(model.layers)\n",
    "        layer_output = K.function([model.layers[0].input],[model.layers[number_of_layers-2].output])\n",
    "\n",
    "\n",
    "\n",
    "        return layer_output([x])[0]\n",
    "\n",
    "    return [[0]*2048]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
